{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tm</th>\n",
       "      <th>Year</th>\n",
       "      <th>PTS_1</th>\n",
       "      <th>VORP_1</th>\n",
       "      <th>PER_1</th>\n",
       "      <th>WS_1</th>\n",
       "      <th>PTS_2</th>\n",
       "      <th>VORP_2</th>\n",
       "      <th>PER_2</th>\n",
       "      <th>WS_2</th>\n",
       "      <th>...</th>\n",
       "      <th>NRtg_2</th>\n",
       "      <th>SRS_2</th>\n",
       "      <th>WinLoss_1</th>\n",
       "      <th>NRtg_1</th>\n",
       "      <th>SRS_1</th>\n",
       "      <th>Rest</th>\n",
       "      <th>B2B</th>\n",
       "      <th>distLB</th>\n",
       "      <th>distUB</th>\n",
       "      <th>WinLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOS</td>\n",
       "      <td>1984</td>\n",
       "      <td>0.691282</td>\n",
       "      <td>1.306881</td>\n",
       "      <td>0.415070</td>\n",
       "      <td>1.050208</td>\n",
       "      <td>0.931111</td>\n",
       "      <td>1.223837</td>\n",
       "      <td>0.082140</td>\n",
       "      <td>0.793457</td>\n",
       "      <td>...</td>\n",
       "      <td>1.560378</td>\n",
       "      <td>1.631836</td>\n",
       "      <td>0.683</td>\n",
       "      <td>1.120777</td>\n",
       "      <td>1.170642</td>\n",
       "      <td>1.244913</td>\n",
       "      <td>-0.368426</td>\n",
       "      <td>-0.359567</td>\n",
       "      <td>0.043129</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NJN</td>\n",
       "      <td>1984</td>\n",
       "      <td>-0.704902</td>\n",
       "      <td>-0.408742</td>\n",
       "      <td>-1.024888</td>\n",
       "      <td>-0.549483</td>\n",
       "      <td>-0.370323</td>\n",
       "      <td>-0.862499</td>\n",
       "      <td>-1.121805</td>\n",
       "      <td>-1.075314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168776</td>\n",
       "      <td>0.223381</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.581578</td>\n",
       "      <td>0.607197</td>\n",
       "      <td>1.244913</td>\n",
       "      <td>-0.881990</td>\n",
       "      <td>-0.736498</td>\n",
       "      <td>-0.606690</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NYK</td>\n",
       "      <td>1984</td>\n",
       "      <td>-0.985729</td>\n",
       "      <td>-0.562171</td>\n",
       "      <td>-0.828808</td>\n",
       "      <td>-0.560477</td>\n",
       "      <td>0.295417</td>\n",
       "      <td>-0.436011</td>\n",
       "      <td>-0.828391</td>\n",
       "      <td>-0.473870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.661303</td>\n",
       "      <td>-0.552811</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.519363</td>\n",
       "      <td>0.565542</td>\n",
       "      <td>-0.544649</td>\n",
       "      <td>0.401919</td>\n",
       "      <td>-0.657416</td>\n",
       "      <td>-0.641871</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PHI</td>\n",
       "      <td>1984</td>\n",
       "      <td>0.803246</td>\n",
       "      <td>1.641637</td>\n",
       "      <td>0.669361</td>\n",
       "      <td>1.462499</td>\n",
       "      <td>1.852632</td>\n",
       "      <td>2.952845</td>\n",
       "      <td>1.327730</td>\n",
       "      <td>2.142409</td>\n",
       "      <td>...</td>\n",
       "      <td>1.389480</td>\n",
       "      <td>1.475055</td>\n",
       "      <td>0.793</td>\n",
       "      <td>1.597761</td>\n",
       "      <td>1.650775</td>\n",
       "      <td>1.244913</td>\n",
       "      <td>0.401919</td>\n",
       "      <td>-1.004836</td>\n",
       "      <td>-0.809547</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WSB</td>\n",
       "      <td>1984</td>\n",
       "      <td>0.400665</td>\n",
       "      <td>2.060082</td>\n",
       "      <td>2.424884</td>\n",
       "      <td>2.451998</td>\n",
       "      <td>-0.118101</td>\n",
       "      <td>0.232539</td>\n",
       "      <td>0.409628</td>\n",
       "      <td>0.518512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217604</td>\n",
       "      <td>0.272215</td>\n",
       "      <td>0.512</td>\n",
       "      <td>-0.019837</td>\n",
       "      <td>0.043753</td>\n",
       "      <td>-0.544649</td>\n",
       "      <td>0.145138</td>\n",
       "      <td>-1.147874</td>\n",
       "      <td>-0.891759</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>MEM</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.788586</td>\n",
       "      <td>1.130905</td>\n",
       "      <td>0.968684</td>\n",
       "      <td>-1.070200</td>\n",
       "      <td>-0.527428</td>\n",
       "      <td>0.347908</td>\n",
       "      <td>-0.031597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204566</td>\n",
       "      <td>0.225057</td>\n",
       "      <td>0.683</td>\n",
       "      <td>1.172994</td>\n",
       "      <td>1.149034</td>\n",
       "      <td>0.038747</td>\n",
       "      <td>-1.149863</td>\n",
       "      <td>0.795401</td>\n",
       "      <td>-0.581626</td>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>OKC</td>\n",
       "      <td>2023</td>\n",
       "      <td>-1.345019</td>\n",
       "      <td>-1.285102</td>\n",
       "      <td>-0.719667</td>\n",
       "      <td>-1.695773</td>\n",
       "      <td>-0.637248</td>\n",
       "      <td>-1.811068</td>\n",
       "      <td>1.053207</td>\n",
       "      <td>-2.128521</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.144903</td>\n",
       "      <td>-2.131412</td>\n",
       "      <td>0.293</td>\n",
       "      <td>-1.665226</td>\n",
       "      <td>-1.690033</td>\n",
       "      <td>-0.007749</td>\n",
       "      <td>-0.308500</td>\n",
       "      <td>0.690877</td>\n",
       "      <td>-0.610994</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>BRK</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.362323</td>\n",
       "      <td>-0.175241</td>\n",
       "      <td>-1.045230</td>\n",
       "      <td>-0.549918</td>\n",
       "      <td>0.205909</td>\n",
       "      <td>0.337065</td>\n",
       "      <td>-0.760419</td>\n",
       "      <td>0.198202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913457</td>\n",
       "      <td>0.892021</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.165220</td>\n",
       "      <td>0.175579</td>\n",
       "      <td>-0.193734</td>\n",
       "      <td>0.532864</td>\n",
       "      <td>-1.076320</td>\n",
       "      <td>-0.404584</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>NOP</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.015879</td>\n",
       "      <td>-0.175241</td>\n",
       "      <td>0.137079</td>\n",
       "      <td>-0.190976</td>\n",
       "      <td>0.612445</td>\n",
       "      <td>0.468048</td>\n",
       "      <td>0.395323</td>\n",
       "      <td>0.471090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058737</td>\n",
       "      <td>-0.042150</td>\n",
       "      <td>0.439</td>\n",
       "      <td>-0.204983</td>\n",
       "      <td>-0.179572</td>\n",
       "      <td>0.038747</td>\n",
       "      <td>-1.149863</td>\n",
       "      <td>-0.013805</td>\n",
       "      <td>0.039575</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>CHO</td>\n",
       "      <td>2023</td>\n",
       "      <td>-0.618961</td>\n",
       "      <td>-0.292069</td>\n",
       "      <td>-0.608290</td>\n",
       "      <td>-0.301420</td>\n",
       "      <td>0.316716</td>\n",
       "      <td>-0.317854</td>\n",
       "      <td>0.347908</td>\n",
       "      <td>-0.318847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382801</td>\n",
       "      <td>-0.408244</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.082953</td>\n",
       "      <td>0.113534</td>\n",
       "      <td>-0.240230</td>\n",
       "      <td>-1.149863</td>\n",
       "      <td>-1.150582</td>\n",
       "      <td>-0.826461</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1076 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tm  Year     PTS_1    VORP_1     PER_1      WS_1     PTS_2    VORP_2  \\\n",
       "0     BOS  1984  0.691282  1.306881  0.415070  1.050208  0.931111  1.223837   \n",
       "1     NJN  1984 -0.704902 -0.408742 -1.024888 -0.549483 -0.370323 -0.862499   \n",
       "2     NYK  1984 -0.985729 -0.562171 -0.828808 -0.560477  0.295417 -0.436011   \n",
       "3     PHI  1984  0.803246  1.641637  0.669361  1.462499  1.852632  2.952845   \n",
       "4     WSB  1984  0.400665  2.060082  2.424884  2.451998 -0.118101  0.232539   \n",
       "...   ...   ...       ...       ...       ...       ...       ...       ...   \n",
       "1126  MEM  2023  0.029700  0.788586  1.130905  0.968684 -1.070200 -0.527428   \n",
       "1127  OKC  2023 -1.345019 -1.285102 -0.719667 -1.695773 -0.637248 -1.811068   \n",
       "1128  BRK  2023  0.362323 -0.175241 -1.045230 -0.549918  0.205909  0.337065   \n",
       "1129  NOP  2023  0.015879 -0.175241  0.137079 -0.190976  0.612445  0.468048   \n",
       "1130  CHO  2023 -0.618961 -0.292069 -0.608290 -0.301420  0.316716 -0.317854   \n",
       "\n",
       "         PER_2      WS_2  ...    NRtg_2     SRS_2  WinLoss_1    NRtg_1  \\\n",
       "0     0.082140  0.793457  ...  1.560378  1.631836      0.683  1.120777   \n",
       "1    -1.121805 -1.075314  ...  0.168776  0.223381      0.598  0.581578   \n",
       "2    -0.828391 -0.473870  ... -0.661303 -0.552811      0.537  0.519363   \n",
       "3     1.327730  2.142409  ...  1.389480  1.475055      0.793  1.597761   \n",
       "4     0.409628  0.518512  ...  0.217604  0.272215      0.512 -0.019837   \n",
       "...        ...       ...  ...       ...       ...        ...       ...   \n",
       "1126  0.347908 -0.031597  ...  0.204566  0.225057      0.683  1.172994   \n",
       "1127  1.053207 -2.128521  ... -2.144903 -2.131412      0.293 -1.665226   \n",
       "1128 -0.760419  0.198202  ...  0.913457  0.892021      0.537  0.165220   \n",
       "1129  0.395323  0.471090  ... -0.058737 -0.042150      0.439 -0.204983   \n",
       "1130  0.347908 -0.318847  ... -0.382801 -0.408244      0.524  0.082953   \n",
       "\n",
       "         SRS_1      Rest       B2B    distLB    distUB  WinLoss  \n",
       "0     1.170642  1.244913 -0.368426 -0.359567  0.043129    0.756  \n",
       "1     0.607197  1.244913 -0.881990 -0.736498 -0.606690    0.549  \n",
       "2     0.565542 -0.544649  0.401919 -0.657416 -0.641871    0.573  \n",
       "3     1.650775  1.244913  0.401919 -1.004836 -0.809547    0.634  \n",
       "4     0.043753 -0.544649  0.145138 -1.147874 -0.891759    0.427  \n",
       "...        ...       ...       ...       ...       ...      ...  \n",
       "1126  1.149034  0.038747 -1.149863  0.795401 -0.581626    0.622  \n",
       "1127 -1.690033 -0.007749 -0.308500  0.690877 -0.610994    0.488  \n",
       "1128  0.175579 -0.193734  0.532864 -1.076320 -0.404584    0.549  \n",
       "1129 -0.179572  0.038747 -1.149863 -0.013805  0.039575    0.512  \n",
       "1130  0.113534 -0.240230 -1.149863 -1.150582 -0.826461    0.329  \n",
       "\n",
       "[1076 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/final_data.csv\")\n",
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df = df[(df.Year <= 2013)]\n",
    "y_train = np.array(first_df.WinLoss)\n",
    "X_train = first_df.drop([\"WinLoss\", \"Year\", \"Tm\"], axis = 1)\n",
    "second_df = df[(df.Year >= 2014)]\n",
    "y_test = np.array(second_df.WinLoss)\n",
    "X_test = second_df.drop([\"WinLoss\", \"Year\", \"Tm\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTS_1</th>\n",
       "      <th>VORP_1</th>\n",
       "      <th>PER_1</th>\n",
       "      <th>WS_1</th>\n",
       "      <th>PTS_2</th>\n",
       "      <th>VORP_2</th>\n",
       "      <th>PER_2</th>\n",
       "      <th>WS_2</th>\n",
       "      <th>PTS_3</th>\n",
       "      <th>VORP_3</th>\n",
       "      <th>...</th>\n",
       "      <th>WinLoss_2</th>\n",
       "      <th>NRtg_2</th>\n",
       "      <th>SRS_2</th>\n",
       "      <th>WinLoss_1</th>\n",
       "      <th>NRtg_1</th>\n",
       "      <th>SRS_1</th>\n",
       "      <th>Rest</th>\n",
       "      <th>B2B</th>\n",
       "      <th>distLB</th>\n",
       "      <th>distUB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.691282</td>\n",
       "      <td>1.306881</td>\n",
       "      <td>0.415070</td>\n",
       "      <td>1.050208</td>\n",
       "      <td>0.931111</td>\n",
       "      <td>1.223837</td>\n",
       "      <td>0.082140</td>\n",
       "      <td>0.793457</td>\n",
       "      <td>0.665685</td>\n",
       "      <td>-0.017425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768</td>\n",
       "      <td>1.560378</td>\n",
       "      <td>1.631836</td>\n",
       "      <td>0.683</td>\n",
       "      <td>1.120777</td>\n",
       "      <td>1.170642</td>\n",
       "      <td>1.244913</td>\n",
       "      <td>-0.368426</td>\n",
       "      <td>-0.359567</td>\n",
       "      <td>0.043129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.704902</td>\n",
       "      <td>-0.408742</td>\n",
       "      <td>-1.024888</td>\n",
       "      <td>-0.549483</td>\n",
       "      <td>-0.370323</td>\n",
       "      <td>-0.862499</td>\n",
       "      <td>-1.121805</td>\n",
       "      <td>-1.075314</td>\n",
       "      <td>-0.155329</td>\n",
       "      <td>-0.800771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.168776</td>\n",
       "      <td>0.223381</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.581578</td>\n",
       "      <td>0.607197</td>\n",
       "      <td>1.244913</td>\n",
       "      <td>-0.881990</td>\n",
       "      <td>-0.736498</td>\n",
       "      <td>-0.606690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.985729</td>\n",
       "      <td>-0.562171</td>\n",
       "      <td>-0.828808</td>\n",
       "      <td>-0.560477</td>\n",
       "      <td>0.295417</td>\n",
       "      <td>-0.436011</td>\n",
       "      <td>-0.828391</td>\n",
       "      <td>-0.473870</td>\n",
       "      <td>0.386474</td>\n",
       "      <td>-0.491076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402</td>\n",
       "      <td>-0.661303</td>\n",
       "      <td>-0.552811</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.519363</td>\n",
       "      <td>0.565542</td>\n",
       "      <td>-0.544649</td>\n",
       "      <td>0.401919</td>\n",
       "      <td>-0.657416</td>\n",
       "      <td>-0.641871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.803246</td>\n",
       "      <td>1.641637</td>\n",
       "      <td>0.669361</td>\n",
       "      <td>1.462499</td>\n",
       "      <td>1.852632</td>\n",
       "      <td>2.952845</td>\n",
       "      <td>1.327730</td>\n",
       "      <td>2.142409</td>\n",
       "      <td>1.046610</td>\n",
       "      <td>1.166702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707</td>\n",
       "      <td>1.389480</td>\n",
       "      <td>1.475055</td>\n",
       "      <td>0.793</td>\n",
       "      <td>1.597761</td>\n",
       "      <td>1.650775</td>\n",
       "      <td>1.244913</td>\n",
       "      <td>0.401919</td>\n",
       "      <td>-1.004836</td>\n",
       "      <td>-0.809547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400665</td>\n",
       "      <td>2.060082</td>\n",
       "      <td>2.424884</td>\n",
       "      <td>2.451998</td>\n",
       "      <td>-0.118101</td>\n",
       "      <td>0.232539</td>\n",
       "      <td>0.409628</td>\n",
       "      <td>0.518512</td>\n",
       "      <td>-0.864992</td>\n",
       "      <td>1.130267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.217604</td>\n",
       "      <td>0.272215</td>\n",
       "      <td>0.512</td>\n",
       "      <td>-0.019837</td>\n",
       "      <td>0.043753</td>\n",
       "      <td>-0.544649</td>\n",
       "      <td>0.145138</td>\n",
       "      <td>-1.147874</td>\n",
       "      <td>-0.891759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>-1.333234</td>\n",
       "      <td>-1.228834</td>\n",
       "      <td>-1.462172</td>\n",
       "      <td>-1.645653</td>\n",
       "      <td>-1.125533</td>\n",
       "      <td>-1.017592</td>\n",
       "      <td>-1.402107</td>\n",
       "      <td>-1.163579</td>\n",
       "      <td>-0.974414</td>\n",
       "      <td>0.598495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280</td>\n",
       "      <td>-1.567634</td>\n",
       "      <td>-1.604512</td>\n",
       "      <td>0.303</td>\n",
       "      <td>-0.997629</td>\n",
       "      <td>-1.082253</td>\n",
       "      <td>0.917020</td>\n",
       "      <td>0.729542</td>\n",
       "      <td>-0.446751</td>\n",
       "      <td>-0.770625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>0.604994</td>\n",
       "      <td>1.388800</td>\n",
       "      <td>1.535243</td>\n",
       "      <td>1.585305</td>\n",
       "      <td>0.330826</td>\n",
       "      <td>0.374367</td>\n",
       "      <td>-0.456866</td>\n",
       "      <td>0.058543</td>\n",
       "      <td>0.356083</td>\n",
       "      <td>-0.390614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.486312</td>\n",
       "      <td>0.560480</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.415679</td>\n",
       "      <td>0.511959</td>\n",
       "      <td>0.059640</td>\n",
       "      <td>-0.422367</td>\n",
       "      <td>0.543168</td>\n",
       "      <td>-0.459561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>-1.122397</td>\n",
       "      <td>-0.886048</td>\n",
       "      <td>0.304961</td>\n",
       "      <td>-0.796134</td>\n",
       "      <td>-1.727405</td>\n",
       "      <td>-1.093864</td>\n",
       "      <td>-0.902633</td>\n",
       "      <td>-1.268795</td>\n",
       "      <td>-1.495970</td>\n",
       "      <td>-1.413253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.281339</td>\n",
       "      <td>0.318</td>\n",
       "      <td>-0.789789</td>\n",
       "      <td>-0.654743</td>\n",
       "      <td>0.137583</td>\n",
       "      <td>-0.038397</td>\n",
       "      <td>0.117796</td>\n",
       "      <td>-0.072959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>-1.618147</td>\n",
       "      <td>-2.537651</td>\n",
       "      <td>-2.148147</td>\n",
       "      <td>-2.536952</td>\n",
       "      <td>-1.538403</td>\n",
       "      <td>-1.551495</td>\n",
       "      <td>0.649495</td>\n",
       "      <td>-1.139298</td>\n",
       "      <td>-1.442750</td>\n",
       "      <td>-1.463546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.847694</td>\n",
       "      <td>-0.896768</td>\n",
       "      <td>0.106</td>\n",
       "      <td>-2.888967</td>\n",
       "      <td>-2.939710</td>\n",
       "      <td>-1.327757</td>\n",
       "      <td>1.113512</td>\n",
       "      <td>-0.433073</td>\n",
       "      <td>-0.841319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1.610333</td>\n",
       "      <td>1.887397</td>\n",
       "      <td>0.319873</td>\n",
       "      <td>1.459966</td>\n",
       "      <td>1.708281</td>\n",
       "      <td>2.376501</td>\n",
       "      <td>1.739744</td>\n",
       "      <td>2.138579</td>\n",
       "      <td>0.949105</td>\n",
       "      <td>1.134961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.803933</td>\n",
       "      <td>0.837423</td>\n",
       "      <td>0.712</td>\n",
       "      <td>1.288604</td>\n",
       "      <td>1.356449</td>\n",
       "      <td>-0.657441</td>\n",
       "      <td>-1.574275</td>\n",
       "      <td>0.757933</td>\n",
       "      <td>-0.613497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PTS_1    VORP_1     PER_1      WS_1     PTS_2    VORP_2     PER_2  \\\n",
       "0    0.691282  1.306881  0.415070  1.050208  0.931111  1.223837  0.082140   \n",
       "1   -0.704902 -0.408742 -1.024888 -0.549483 -0.370323 -0.862499 -1.121805   \n",
       "2   -0.985729 -0.562171 -0.828808 -0.560477  0.295417 -0.436011 -0.828391   \n",
       "3    0.803246  1.641637  0.669361  1.462499  1.852632  2.952845  1.327730   \n",
       "4    0.400665  2.060082  2.424884  2.451998 -0.118101  0.232539  0.409628   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "825 -1.333234 -1.228834 -1.462172 -1.645653 -1.125533 -1.017592 -1.402107   \n",
       "826  0.604994  1.388800  1.535243  1.585305  0.330826  0.374367 -0.456866   \n",
       "827 -1.122397 -0.886048  0.304961 -0.796134 -1.727405 -1.093864 -0.902633   \n",
       "828 -1.618147 -2.537651 -2.148147 -2.536952 -1.538403 -1.551495  0.649495   \n",
       "829  1.610333  1.887397  0.319873  1.459966  1.708281  2.376501  1.739744   \n",
       "\n",
       "         WS_2     PTS_3    VORP_3  ...  WinLoss_2    NRtg_2     SRS_2  \\\n",
       "0    0.793457  0.665685 -0.017425  ...      0.768  1.560378  1.631836   \n",
       "1   -1.075314 -0.155329 -0.800771  ...      0.537  0.168776  0.223381   \n",
       "2   -0.473870  0.386474 -0.491076  ...      0.402 -0.661303 -0.552811   \n",
       "3    2.142409  1.046610  1.166702  ...      0.707  1.389480  1.475055   \n",
       "4    0.518512 -0.864992  1.130267  ...      0.524  0.217604  0.272215   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "825 -1.163579 -0.974414  0.598495  ...      0.280 -1.567634 -1.604512   \n",
       "826  0.058543  0.356083 -0.390614  ...      0.561  0.486312  0.560480   \n",
       "827 -1.268795 -1.495970 -1.413253  ...      0.561  0.189867  0.281339   \n",
       "828 -1.139298 -1.442750 -1.463546  ...      0.415 -0.847694 -0.896768   \n",
       "829  2.138579  0.949105  1.134961  ...      0.671  0.803933  0.837423   \n",
       "\n",
       "     WinLoss_1    NRtg_1     SRS_1      Rest       B2B    distLB    distUB  \n",
       "0        0.683  1.120777  1.170642  1.244913 -0.368426 -0.359567  0.043129  \n",
       "1        0.598  0.581578  0.607197  1.244913 -0.881990 -0.736498 -0.606690  \n",
       "2        0.537  0.519363  0.565542 -0.544649  0.401919 -0.657416 -0.641871  \n",
       "3        0.793  1.597761  1.650775  1.244913  0.401919 -1.004836 -0.809547  \n",
       "4        0.512 -0.019837  0.043753 -0.544649  0.145138 -1.147874 -0.891759  \n",
       "..         ...       ...       ...       ...       ...       ...       ...  \n",
       "825      0.303 -0.997629 -1.082253  0.917020  0.729542 -0.446751 -0.770625  \n",
       "826      0.621  0.415679  0.511959  0.059640 -0.422367  0.543168 -0.459561  \n",
       "827      0.318 -0.789789 -0.654743  0.137583 -0.038397  0.117796 -0.072959  \n",
       "828      0.106 -2.888967 -2.939710 -1.327757  1.113512 -0.433073 -0.841319  \n",
       "829      0.712  1.288604  1.356449 -0.657441 -1.574275  0.757933 -0.613497  \n",
       "\n",
       "[784 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=4, test_size=188, gap = 0)\n",
    "\n",
    "num_estimators= [i for i in range(20, 121, 20)]\n",
    "max_depth = [3, 4, 5, 6]\n",
    "alpha = [0.5, 0.7, 1, 1.2, 1.5]\n",
    "lam = [0.5, 0.7, 1, 1.2, 1.5]\n",
    "col_sampletree = [0.7, 0.8, 0.9, 1]\n",
    "gamma = [0, 0.1, 0.2]\n",
    "\n",
    "score = []\n",
    "for num_esti in num_estimators:\n",
    "    for md in max_depth:\n",
    "        for a in alpha:\n",
    "            for l in lam:\n",
    "                for cst in col_sampletree:\n",
    "                    for gam in gamma:\n",
    "                        res = [num_esti, md, a, l, cst, gam]\n",
    "                        rmse = []\n",
    "                        ratio = 1\n",
    "                        for train_index, test_index in tscv.split(X_train):\n",
    "                            cv_train, cv_val = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "                            cv_y_train, cv_y_val = y_train[train_index], y_train[test_index]\n",
    "                            model = XGBRegressor(n_estimators = num_esti, max_depth = md, reg_alpha = a, reg_lambda = l,\n",
    "                                                colsample_bytree = cst, gamma = gam, eta = 0.3)\n",
    "                            model.fit(cv_train, cv_y_train) \n",
    "                            rmse.append(ratio*np.sqrt(mean_squared_error(model.predict(cv_val), cv_y_val)))\n",
    "                            ratio +=1\n",
    "                        res.append(np.sum(rmse)/10)\n",
    "                        score.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winloss_win(arr):\n",
    "    return 82*np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_estimators    40.000000\n",
      "max_depth          5.000000\n",
      "alpha              0.500000\n",
      "lambda             1.500000\n",
      "col_sampletree     0.700000\n",
      "gamma              0.000000\n",
      "rmse               0.128528\n",
      "Name: 1848, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score of the train set : 0.9017211682271217\n",
      "R2 score of the train set : -0.03949246226593828\n",
      "MAE score of the train set : 2.588935250947583\n",
      "MAE score of the test set : 7.6199559540985335\n"
     ]
    }
   ],
   "source": [
    "score = pd.DataFrame(score, columns = [\"num_estimators\", \"max_depth\", \"alpha\", \"lambda\", \"col_sampletree\", \"gamma\", \"rmse\"])\n",
    "score.sort_values(by=['rmse'], ascending=False, inplace = True)\n",
    "best_params = list(score.iloc[0, :])[:-1]\n",
    "print(score.iloc[0, :])\n",
    "\n",
    "evalset = [(X_train, y_train), (X_test,y_test)]\n",
    "model = XGBRegressor(n_estimators = int(best_params[0]), max_depth = int(best_params[1]), \n",
    "                     reg_alpha = best_params[2], reg_lambda = best_params[3],\n",
    "                     colsample_bytree = best_params[4], gamma = best_params[5], eta = 0.3)\n",
    "\n",
    "model.fit(X_train, y_train, eval_set = evalset, verbose = 0)\n",
    "results = model.evals_result()\n",
    "plt.plot(results['validation_0']['rmse'], label='train')\n",
    "plt.plot(results['validation_1']['rmse'], label='test')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "pred_train = winloss_win(model.predict(X_train))\n",
    "pred_test = winloss_win(model.predict(X_test))\n",
    "y_train_win = winloss_win(y_train)\n",
    "y_test_win = winloss_win(y_test)\n",
    "\n",
    "print(f\"R2 score of the train set : {r2_score(pred_train, y_train_win)}\")\n",
    "print(f\"R2 score of the train set : {r2_score(pred_test, y_test_win)}\")\n",
    "print(f\"MAE score of the train set : {mean_absolute_error(pred_train, y_train_win)}\")\n",
    "print(f\"MAE score of the test set : {mean_absolute_error(pred_test, y_test_win)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour ne pas à devoir ReRun le Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtEklEQVR4nO3deXyU5b3//9dnJpOE7MkkJCRhSdj3LSyKKIgoKm6tu1bbo7W1aj091SN+u5zq93v6sP31VK3VWmypVepWbY9WqCKLS5EtIAZCgAQIkIWsZCV7rt8f94SEEDCEJPdk5vN8PO7H3NvMfHJD3nPluq+5bzHGoJRSync57C5AKaVU39KgV0opH6dBr5RSPk6DXimlfJwGvVJK+bgAuwvoLDY21owYMcLuMpRSakDZvn17qTEmrqttXhf0I0aMID093e4ylFJqQBGRw2fapl03Sinl4zTolVLKx2nQK6WUj/O6PnqllOqJpqYm8vLyqK+vt7uUPhUcHExycjIul6vbz9GgV0r5hLy8PMLDwxkxYgQiYnc5fcIYQ1lZGXl5eaSkpHT7edp1o5TyCfX19bjdbp8NeQARwe12n/NfLRr0Simf4csh36YnP6PPBH3FiUaeXZvN7vxKu0tRSimv4jNB73AIz67bz5o9RXaXopTyQxUVFbzwwgvn/LyrrrqKioqK3i+oA58J+ohgFxMTI9lysMzuUpRSfuhMQd/c3HzW561evZqoqKg+qsriM0FPTTFPyHKajm6nvqnF7mqUUn5m2bJlHDhwgGnTpjFr1izmz5/Ptddey4QJEwC4/vrrmTlzJhMnTmT58uUnnzdixAhKS0vJzc1l/PjxfPvb32bixIlcfvnl1NXV9UptvjO8MiCYKRVr+YaUsvPobcxNddtdkVLKJk/8I5M9BVW9+poTEiP4r2smnnH7U089xe7du9m5cycff/wxV199Nbt37z45DHLFihXExMRQV1fHrFmz+PrXv47bfWpOZWdn8/rrr/PSSy9x8803884773DnnXeed+2+06IPjqBl6h1c7dhMxt59dlejlPJzs2fPPmWs+29+8xumTp3K3LlzOXr0KNnZ2ac9JyUlhWnTpgEwc+ZMcnNze6UW32nRA0EXfpfW7S/h3vMqXHWh3eUopWxytpZ3fwkNDT05//HHH7N27Vo2bdpESEgICxYs6HIsfFBQ0Ml5p9PZa103vtOiB3CPJCfyQhZUv09Dfa3d1Sil/Eh4eDjV1dVdbqusrCQ6OpqQkBD27t3L5s2b+7U23wp6oGrqvbilivzP/mJ3KUopP+J2u5k3bx6TJk3i0UcfPWXbkiVLaG5uZvz48Sxbtoy5c+f2a21ijOnXN/wqaWlp5nxuPFJR20DRL2YQEx5C3CNbwQ++KaeUgqysLMaPH293Gf2iq59VRLYbY9K62t/nWvRRoUF8EHY9cbX74fDndpejlFK287mgB6gZ8zUqTBitm39ndylKKWU7nwz6maOSeK3lUmTfKjh+xtsoKqWUX/DJoJ+dEsOrzYsxRmDbS3aXo5RStvLJoI8JDSQyYQRbB10E21+Bhhq7S1JKKdv4ZNADzEmJ4dmaRdBQCV++bnc5SillG58N+rmpbjY1jaQ2dips+T20ttpdklLKh/X0MsUAzzzzDCdOnOjlitr5bNDPTokBhM/jboSybDiw3u6SlFI+zJuD3qeuddOROyyIMfFhvFYzk8VhCbDldzD6MrvLUkr5qI6XKV68eDGDBw/mrbfeoqGhgRtuuIEnnniC2tpabr75ZvLy8mhpaeEnP/kJRUVFFBQUsHDhQmJjY9mwYUOv1+azQQ8wJ8XN33bk0bLw33B+8nMo2Q9xY+wuSynV1/65DI7t6t3XTJgMVz51xs0dL1O8Zs0a3n77bbZu3YoxhmuvvZZPP/2UkpISEhMTWbVqFWBdAycyMpJf//rXbNiwgdjY2N6t2aNbXTciskRE9olIjogs62L7xSKyQ0SaReTGDuunicgmEckUkQwRuaU3i/8qc1Pd1Da2sCfxa+AMhK2/78+3V0r5qTVr1rBmzRqmT5/OjBkz2Lt3L9nZ2UyePJmPPvqIxx57jM8++4zIyMh+qecrW/Qi4gSeBxYDecA2EXnPGLOnw25HgG8Cj3R6+gngLmNMtogkAttF5ENjTEVvFP9VrH562HjMweTJN8HO12DB4xDaN5+aSikvcZaWd38wxvD444/zne9857RtO3bsYPXq1fz4xz9m0aJF/PSnP+3zerrTop8N5BhjDhpjGoE3gOs67mCMyTXGZACtndbvN8Zke+YLgGIgrlcq74a48CBGDQ5j88EyuPAhMK3w2i3QqJcwVkr1ro6XKb7iiitYsWIFNTXWd3jy8/MpLi6moKCAkJAQ7rzzTh599FF27Nhx2nP7Qnf66JOAox2W84A55/pGIjIbCAQOnOtzz8eclBje3VlAszuNgBtXwJt3wlt3w22vg9PVn6UopXxYx8sUX3nlldx+++1ccMEFAISFhbFy5UpycnJ49NFHcTgcuFwufvc763pc9913H0uWLCExMXHgnowVkSHAq8DdxpjTBrSLyH3AfQDDhg3r1feem+rmL1uOkFlQxdRxV8PSZ+Af34d3H4DrXwSHz44wVUr1s9dee+2U5YcffviU5ZEjR3LFFVec9ryHHnqIhx56qM/q6k7K5QNDOywne9Z1i4hEAKuAHxljurytijFmuTEmzRiTFhfXuz07c1Ktfvoth8qsFTPvhkt/DBlvwtq+7xtTSim7dSfotwGjRSRFRAKBW4H3uvPinv3/DrxijHm752X23ODwYFLjQtl8sLx95fxHYPZ34PPnYONv7ChLKaX6zVcGvTGmGXgQ+BDIAt4yxmSKyJMici2AiMwSkTzgJuD3IpLpefrNwMXAN0Vkp2ea1hc/yNnMSXGz7VA5La2eu2mJwJKnYOIN8NFPYKdeC0cpX+Btd8zrCz35GbvVR2+MWQ2s7rTupx3mt2F16XR+3kpg5TlX1cvmpsbw+tYj7CmoYnKyZ9yqwwE3/B5OlFv99SFuGHO5vYUqpXosODiYsrIy3G430vEWosZAazO0toBpsUbfAeDZ55TbjYpn2fMojg7LnnljrNc4+dgKdFjnCABnAIiz129laoyhrKyM4ODgc3qeT38zts3cVDdg9dOfDHqAgCC49S/w8tXw17vhrvdg6CybqlRKnaa1FZpOWFNjjTU0urEW6itPm5IbG8iLnktJYMypIXz6+I/zIEB3W9QCDqfnA8JpNS7FYa2Xttfi1GVxQmDIWV81ODiY5OTT2tVn5RdBHx8RTEpsKJsPlnHv/NRTNwaFwx3vwIrLYeXXYOGPYNY9OvRSqa/S1lJurofmBs9U38Vj/anLTfVWaDdUdzFVWo+NtdB4Apq6+Z2XgGBcwZGkBG+A4EgYFAODorueAoJob4G3nto6b22B1iZoboSWhvafq6XBs67R+pa9KxgCPJNrUPu8wwEnjkNtiWcqhtrS9uW6Suv1W5uhpYnTPjSSZ8G9a3v7X8o/gh6s8fSrdxXS0mpwOjr9ORUWB3e9C+99Hz54DLb/yerDH7nQnmKVOl+tLVa35Ikyz1RqPdZ6luuOW61Lp8sKroCg9nmnCxArcLtoOVNfaQV1c/35tZYdLgiOsBpbQeEQFAERSdZ8YCgEhlmPrpAOy5754Cgr0IMjree5zq0rw2u0tnYK/r7hN0E/N9XNG9uOkllQyZTkqNN3iBoG3/g77FsNH/4fePV6GLcUrvhviB7Rz9Uq2xkDFUeg8mh7YNaVe+bL2+dFTm3VdXx0DbLCKSjcE0jhp04BwVZo1h33TBUd5o9bLcmAQGu/tjAOCAKn57G5oUOIl1stx7blugrO2MUQFAGDoqzNLY2nT20cLmu/4Mj2YI0a5vlZwjyt2CBPfUHt8201n5yC2h9dg6x9g8I8LWs/53CAIwjo22PhN0F/yZg4AhzC6l3Hug56sH5px10NIxfBpt/CZ/8Dv50N874PF/3Aakko39PSbN2zoDADCr+EYxnWVF95+r6uEKtbIMTTNQBWy7bueHu3RHOd9dh0wjr5d67EYQWra5Cn26DReu2OIdzGEWANJAiJtWpKmOSZd1vXdAqJaV9umwICz/zeHU9cBgT1+slEZQ/xtuFIaWlpJj09vU9e++4VWzlQUsNn/7nw1LPyZ1JVAB/9F+x6y/qTcu73IH4CuEdBRLJ+q9bb1FfB8dz2qeIwVB+zwqutdXvy/7vnsbYEijKtIAWr5Rk/ERKmwJApEJPqCXa3FZquQd2vxxjrdU/2P1d5ukM8j831nv7kqFP7kAPDu/6/1draHvrNDVYQB0dqGCsARGS7MSatq21+06IHuGZqIo/89Ut2Hq1g+rDor35CRCJ8/SXr5Ow/H4M1P2rfFhAMMSMhdpQV/G1TTKoVCvrL13fqq6BwJ+TvsFre5YesYK8rP3W/4EgIT7RavdA+yKHjsLqgCEi7xwr1hCkQO8YaGtcbRNq7cMIGn//rORzgCB64/dHKNn4V9JdPjCfwbw7ezyjsXtC3GTYX7vsYaoqgNBvKctqnokzYu8r6c7dNUCTEpFih33GKHQOh7l7/uXqdMVB+EPLSIT8dirOsVmd4IkQMOf3xXLq0muqtbpLivVDimUyr1c0QOtgKxNA4awobbLWmjx+yQr1gBxR8Yf0btLXIo4aBezQkTrPOpUQNtx6jh7d3rSjl5/wq6COCXVw8Jo5VGYX86KrxODqPvjkbEQhPsKaU+adua2myWpTlB0+dCnfCnndP7acNiYW4cdadruLGQdxYiB1rva5dfwWcKLeCNG+bFez5260+ZwBXKAweb33IHfgYGru4lGpguBWqbd0QbSfv2uabG6xAL86yQrttpIY4rQ/AgGDrPWtLz96nHZYASTNg8s2QNB0SZ1jdKUqps/KroAe4ZuoQ1mYVkX74+Mkbk5w3pwtiR1tTZy1N1uiN8oNQut/Tit0Hu9859WRfcCQkpVl/PQydA8lpvX/yt6neE7h7rL9EirOs+epCzw5ihfq4pdb7J6VZH0YduzIaqqGqEKoL2h9rij2jRyqsx/KD7ctNtVagu0dZfd+Tb7Q+3OLGg3vkqSMvWlut7pea4g7jj0shMtkK+IjE3j0eSvkJvwv6y8bHE+xy8H5GQe8F/dk4XVaguUfC6MXt642xAq1kr/UBULQbjm6FDT8HjBWOQ6bA0LkwbI7VfxwQbPU3OwKsb9w5nO3LzfXW67WFZNt8TZH1WJYD5QfaW9POICtwUy6xTjAnTremoPCz/zxB4RAX3v1777aNDe7OF9AcDk8XTiwwoXuvr5T6Sn4X9KFBAVw6bjCrdxXy06UTCHDaNHJGBMLjrSn1kvb1dRVWF8qRTXBkC2x/Gbb8rqdv0t7XHTfWuohb/AQYPNHqMumtk45no98wVsp2fhf0AEunJLJ61zG2HCpn3igvu3/soCir5d/W+m9pssZ3l+z1jG/2jHFumzeeeYcLwuKtb/mGxVtTiNtq9Sul/JpfBv3CsYMJDXTyfkaB9wV9Z04XJM+0JqWU6gG//MbPoEAnl02I55+7j9HU0ptXtlNKKe/jl0EPVvdNxYkm/pVTancpSinVp/w26C8eE0t4cADvf1n41TsrpdQA5rdBHxTg5IqJCazJPEZDcw8uPKWUUgOE3wY9wNIpQ6huaOaTfSV2l6KUUn3Gr4N+3qhYokNcvJ+h3TdKKd/l10HvcjpYMsm6JEJdo3bfKKV8k18HPcA1U4ZworGF9XuL7S5FKaX6hN8H/ZxUN7FhQbyfUWB3KUop1Sf8PuidDuHqyQms31tMTUPzVz9BKaUGGL8PeoClUxNpaG5l7Z4iu0tRSqlep0EPzBwWTUJEsHbfKKV8kgY94HAIS6cM4ZP9JRRU1NldjlJK9SoNeo+7LxyBIPxmXbbdpSilVK/SoPcYGhPCHXOH8Vb6UXKKa+wuRymleo0GfQcPLBzFIJeTX3+0z+5SlFKq12jQdxAbFsS981NZvesYXx6tsLscpZTqFRr0ndw7P4WY0EB++eFeu0tRSqleoUHfSXiwiwcWjmJjThn/ytabkiilBj4N+i7cMWcYSVGD+MUHezHG2F2OUkqdFw36LgS7nPxg8Rh25Vfyz93H7C5HKaXOiwb9GdwwPYnRg8P41Yf7aNYbiCulBrBuBb2ILBGRfSKSIyLLuth+sYjsEJFmEbmx07a7RSTbM93dW4X3NadDePSKsRwsreXt7Xl2l6OUUj32lUEvIk7geeBKYAJwm4hM6LTbEeCbwGudnhsD/BcwB5gN/JeIRJ9/2f1j8YR4pg+L4pm12dQ36Y1JlFIDU3da9LOBHGPMQWNMI/AGcF3HHYwxucaYDKBzH8cVwEfGmHJjzHHgI2BJL9TdL0SEx5aM41hVPa9syrW7HKWU6pHuBH0ScLTDcp5nXXd067kicp+IpItIekmJd92oe26qm0vGxPH8hgNU1jXZXY5SSp0zrzgZa4xZboxJM8akxcXF2V3Oaf5zyVgq65pY/ukBu0tRSqlz1p2gzweGdlhO9qzrjvN5rteYmBjJddMS+cNnhzhafsLucpRS6px0J+i3AaNFJEVEAoFbgfe6+fofApeLSLTnJOzlnnUDzrIrx+F0CE/8Y4/dpSil1Dn5yqA3xjQDD2IFdBbwljEmU0SeFJFrAURklojkATcBvxeRTM9zy4H/i/VhsQ140rNuwBkSOYiHF41mbVYR6/fqLQeVUgOHeNtX/NPS0kx6errdZXSpsbmVK5/9lKYWw5ofXEywy2l3SUopBYCIbDfGpHW1zStOxg4UgQEOnrxuEkfKT/D7Tw7aXY5SSnWLBv05mjcqlqVThvDCxzkcKdMTs0op76dB3wM/vnoCTofw5PuZdpeilFJfSYO+BxIigz0nZotZl6UnZpVS3k2Dvoe+NS+FUYPD+Nk/MvU6OEopr6ZB30OBAQ6evHYiR8vrePET/casUsp7adCfhwtHxXLN1ERe+PiAnphVSnktDfrz9KOrxuNyCE/8Q0/MKqW8kwb9eUqIDObhy0azbm8xH+3RE7NKKe+jQd8LvjUvhbHx4Sx7J4P8ijq7y1FKqVNo0PcCl9PBC3fOoKG5lftXbtdROEopr6JB30tGxoXx65unkpFXyY//dzfedg0hpZT/0qDvRZdPTOD7l47i7e15rNx82O5ylFIK0KDvdf9+2RgWjo3jiX/sYVvugLwis1LKx2jQ9zKHQ3jm1ukkRw/i/pU7OFZZb3dJSik/p0HfByIHuVh+VxonGpu5/y/baWjWk7NKKfto0PeRMfHh/OqmqXxxpEJvP6iUspUGfR+6avIQ7l8wkte2HOGNrUfsLkcp5ac06PvYI5ePZf7oWH76biaf55TaXY5Syg9p0Pcxp0N47rbpDHOHcNeKrby6KVfH2Cul+pUGfT+ICgnkb9+7kIvHxPGTdzP5P3/fRWNzq91lKaX8hAZ9P4kIdvHSXWk8sHAkr289ym0vbaa4WodeKqX6ngZ9P3I6hEevGMdzt00ns6CSa5/bSEZehd1lKaV8nAa9Da6Zmsg791+I0yHc9OIm/v5Fnt0lKaV8mAa9TSYmRvLeg/OYNjSKH7z5JT9fnUVLq56kVUr1Pg16G7nDglh57xzuumA4yz89yL+/uZOmFj1Jq5TqXQF2F+DvXE4HT143icSoQTz1z73UNTbz29tnEOxy2l2aUspHaIveS3z3kpH83+snsW5vMf/28jZqG5rtLkkp5SM06L3IN+YO59c3T2XLoXLu/OMWKk802V2SUsoHaNB7mRumJ/P87TPIzK/i1pc2U1rTYHdJSqkBToPeCy2ZlMAf7k7jUGkNN7+4iQK94bhS6jxo0Hupi8fE8eo9cyipbuCmFzeRW1prd0lKqQFKg96LzRoRw+v3zeVEYzM3vriJ7YeP212SUmoA0qD3cpOSIvnrdy8gJNDJbcs38+Y2va69UurcaNAPAKMGh/Peg/OYkxrDY+/s4qfv7tYvVimluq1bQS8iS0Rkn4jkiMiyLrYHicibnu1bRGSEZ71LRP4sIrtEJEtEHu/l+v1GVEggf/rmLL49P4VXNh3mzj9soUxH5CiluuErg15EnMDzwJXABOA2EZnQabd7gOPGmFHA08AvPOtvAoKMMZOBmcB32j4E1LkLcDr40dUTeOaWaew8WsG1v93I7vxKu8tSSnm57rToZwM5xpiDxphG4A3guk77XAf82TP/NrBIRAQwQKiIBACDgEagqlcq92PXT0/i7e9eSKsx3Pji57y7M9/ukpRSXqw7QZ8EHO2wnOdZ1+U+xphmoBJwY4V+LVAIHAF+ZYwpP8+aFTA5OZL3HryIyUmRPPzGTp76515a9eqXSqku9PXJ2NlAC5AIpAA/FJHUzjuJyH0iki4i6SUlJX1cku+ICw/iL/fO5Y45w3jxkwM88NoO6hpb7C5LKeVluhP0+cDQDsvJnnVd7uPppokEyoDbgQ+MMU3GmGJgI5DW+Q2MMcuNMWnGmLS4uLhz/yn8WGCAg/93/SR+snQCH2Qe49aXNlNSrSdplVLtuhP024DRIpIiIoHArcB7nfZ5D7jbM38jsN4YY7C6ay4FEJFQYC6wtzcKV+1EhHsuSuH3d85k/7Fqrn9+I9lF1XaXpZTyEl8Z9J4+9weBD4Es4C1jTKaIPCki13p2+yPgFpEc4D+AtiGYzwNhIpKJ9YHxJ2NMRm//EMpy+cQE3vzOXBpbWvna7z7nX9mldpeklPICYjW8vUdaWppJT0+3u4wBLb+ijn/70zYOlNTw3zdM4pZZw+wuSSnVx0RkuzHmtK5x0G/G+qSkqEG8ff8FXDDSzWPv7OIXH+iIHKX8mQa9jwoPdrHim7O4bfYwfvfxAb718jYOl+kVMJXyRxr0PszldPDzGybx5HUTSc8tZ/HTn/L0R/upb9IhmEr5Ew16Hyci3HXBCNY/soAlExN4dl02lz/9KRv2FttdmlKqn2jQ+4n4iGB+c9t0Xrt3DoEBDr718ja+/Uo6R8tP2F2aUqqPadD7mQtHxbL6+/NZduU4NuaUsvjpT/jt+mwamrU7RylfpUHvhwIDHHz3kpGs/Y9LuHTcYH61Zj+L/ucT3t2Zr6NzlPJBGvR+LDFqEC/cMZO/3DuHiGAXD7+xk+ue38jnB/SLVkr5Eg16xbxRsbz/0EU8fctUymsbuf2lLfzby9vYr5dRUMonaNArABwO4Ybpyaz74SU8fuU4tuWWs+SZT1n2TgZFVfV2l6eUOg96CQTVpeO1jTy3PodXN+fidAjXT0vijjnDmZwcaXdpSqkunO0SCBr06qyOlJ3g+Q05vPtlPvVNrUxJjuSOOcO4ZmoiIYEBdpenlPLQoFfnrbKuif/9Ip/XthxhX1E14UEB3DAjidvnDGNcQoTd5Snl9zToVa8xxrD98HFe23KE93cV0tjcyqwR0TywcBSXjInDulWwUqq/adCrPnG8tpF3duTxp4255FfUMXVoFP++aDQLxmrgK9XfNOhVn2psbuWdHXk8vyGHvON1TE2O5PuLRnPpuMEa+Er1Ew161S+aWlr52448nltvBf7kpEgeXjSaReM18JXqa3rjEdUvXE4Ht8waxoZHFvDLr0+hsq6Je19J5/rnN7LjyHG7y1PKb2nQq17ncjq4edZQ1v3wEn554xSOVdXztRc+54dvfUlxtX75Sqn+pkGv+ozL6eDmtKGs/+EC7l8wkn98WcClv/qE5Z8eoLG51e7ylPIbGvSqz4UGBfDYknF8+IOLmZMSw89X72XJs5/yyf4Su0tTyi9o0Kt+kxIbyh+/OYs/fXMWxsDdK7by7VfSOVSq97JVqi/pqBtli4bmFlb8K5fn1mdT39TCVZOHcP+CkUxM1GvpKNUTOrxSea3i6npW/CuXlZsPU9PQzIKxcXxvwShmp8TYXZpSA4oGvfJ6lXVNrNx8mD/+6xDltY2kDY/mewtHsnCsjsFXqjs06NWAUdfYwpvbjvDSZ4fIr6hjXEI4DywcxVWTh+B0aOArdSYa9GrAaWpp5b2dBbzwcQ4HSmoZNTiMhy4dxdIpiRr4SnVBg14NWC2thtW7CnlufTb7i2pIjQ3lwUtHce3URAKcOmhMqTYa9GrAa201fJB5jN+sy2bvsWpGuEN4YOEobpiepIGvFBr0yoe0thrW7CniN+uy2VNYxbCYEH54+RiumZKIQ7t0lB/Ti5opn+FwCEsmJbDq+xfx0l1phAYF8PAbO7nu+Y1sOlBmd3lKeSUNejUgiQiLJ8Sz6qGL+J+bplJW08BtL23mnpe3kV1UbXd5SnkVDXo1oDkcwtdnJrP+kQU8tmQcWw+Vc8Uzn/L43zIortIrZSoF2kevfEx5bSPPrc9m5ebDuJwO7r0ohW/NSyE6NNDu0pTqU3oyVvmdw2W1/PLDfazKKCTYZV0u+Z6LUhjuDrW7NKX6hAa98lv7i6r5w2cH+d8vCmhqbWXJxATunZ/KzOHRdpemVK8676AXkSXAs4AT+IMx5qlO24OAV4CZQBlwizEm17NtCvB7IAJoBWYZY87YeapBr/pCcVU9f96Uy8rNR6isa2Lm8Gi+PT+VxRPi9Zu2yiecV9CLiBPYDywG8oBtwG3GmD0d9vkeMMUY810RuRW4wRhzi4gEADuAbxhjvhQRN1BhjGk50/tp0Ku+VNvQzF/Tj/LHjYc4Wl7HcHcI35g7nJvShhI5yGV3eUr12PmOo58N5BhjDhpjGoE3gOs67XMd8GfP/NvAIrEuOXg5kGGM+RLAGFN2tpBXqq+FBgXwzXkpbPjhAp6/fQZxYUH8v1VZzP35On70913s16GZygcFdGOfJOBoh+U8YM6Z9jHGNItIJeAGxgBGRD4E4oA3jDG/7PwGInIfcB/AsGHDzvVnUOqcBTgdXD1lCFdPGcLu/Er+/Hkuf92ex1+2HOGCVDd3XziCy8YP1ssrKJ/QnaA/39e/CJgFnADWef68WNdxJ2PMcmA5WF03fVyTUqeYlBTJ/3fTVB6/ajxvbjvKys2H+e7K7SRFDeKmtGSWTklk1OAwu8tUqse6E/T5wNAOy8medV3tk+fpl4/EOimbB3xqjCkFEJHVwAxgHUp5mZjQQO5fMJJvz09hbVYxr2zK5dl12TyzNptxCeFcPdn6CyA1TkNfDSzdORkbgHUydhFWoG8DbjfGZHbY5wFgcoeTsV8zxtwsItFYoX4R0Ah8ADxtjFl1pvfTk7HKmxRV1bN6VyGrMgpJP3wcgAlDIqxun8lDGBGr4/KVd+iN4ZVXAc9gDa9cYYz5bxF5Ekg3xrwnIsHAq8B0oBy41Rhz0PPcO4HHAQOsNsb859neS4NeeavCyjpW7zrGqowCdhypAGBqciTXT0/imqmJxIYF2Vug8mv6hSmlell+RR2rMgr43y8K2FNYhdMhXDImjhumJ7F4QjzBLqfdJSo/o0GvVB/ad6yav32Rx7tfFHCsqp6woACunJTADTOSmJPi1i9kqX6hQa9UP2hpNWw5WMbfvsjnn7sKqW1sISY0kEvHDWbxhHjmj44lJLCvB7opf6VBr1Q/q2tsYf3eYtbsOcaGvcVU1TcTFOBg/uhYLhsfz6Lx8cSFa5++6j0a9ErZqKmlla2HyvloTxEf7Skiv6IOEZgxLJqrJlujdxIig+0uUw1wGvRKeQljDFmF1Xy0p4gPMo+RVVgFwKwR0SydksiVkxIYHKGhr86dBr1SXupASQ2rMqxx+vuKqhGB2SNiWDo1kSUTE7R7R3WbBr1SA0B2UTXvZxTyfkYBB0pqARg/JIKLRrmZNyqW2SkxejJXnZEGvVIDiDGGvceqWb+3mI05paTnHqexpRWXU5gxLJqLRsUyb3QsU5Ii9aJr6iQNeqUGsLrGFtIPl/OvnFI25pSSWVCFMda1ea6YGM/VkxOZmxqjoe/nNOiV8iHltY18fqCUDzOLWJdVxAnPeP0rJsZz1eQhXJDq1tD3Qxr0Svmo+qYWPt5XwqpdhSdDPzrExZJJCRr6fkaDXik/0FXoa/eO/9CgV8rPWKFfzKpdxzqFfgJXTx6ioe+DNOiV8mNdhb47NJAlkxK4dmois0bE4NALrw14GvRKKaA99N/PKGRdVjF1TS0MiQxm6ZQhXDM1kclJkYho6A9EGvRKqdPUNjSzNquIf3xZwCf7S2hqMYxwh3Dt1ESWTk1k9OAwDf0BRINeKXVWlSea+CCzkPe+LGDTgTJaDQx3h7BoXDyLxg9m1ogYAgO0T9+badArpbqtuLqeDzOLWJ9VxMYDZTQ2txIeFMDFY+K4dNxgFo4bTExooN1lqk406JVSPXKisZmNOWWs31vEuqxiiqsbTl5i+bLx8SyeEM/IuFDt4vECGvRKqfPW2mrILKhibVYR6/cWsyu/EoCU2FAuGz+Yy8bHM3N4tA7btIkGvVKq1xVW1rE2q5i1e4rYdKCMxpZWokNcLBw3mAVjBzM3JUavrd+PNOiVUn2qpqGZT/eXsHZPEev3FVNxogmwWvtzUmKYkxrDnBQ3iVGDbK7Ud2nQK6X6TXNLK3sKq9hysJwth8rYeqicqvpmAIbGDGJOipuZw6OZnBTJ2IRwXNrV0ys06JVStmlpNWQVVrHlUDlbDpaxNbf8ZIs/MMDB+CERTEmKZEpyJFOSoxgZF6r9/D2gQa+U8hrGGI6UnyAjr5Jd+ZVk5FWwO7+Kmgar1R/scpASG0ZqbCgpsaGM8DymxIYSHeLSET5ncLag1/uSKaX6lYgw3B3KcHco10xNBKwRPYfKatnlCf+DJTXsKazig8xjtLS2N0YjB7lIjQtlXEI4E4ZEMH5IBOOGRBAWpFF2NtqiV0p5raaWVvKO13GotIaDJbXkltWSU1xDVmE1lXVNJ/cb7g5hfIIV/OOHhDN+SARJUYP86mJt2qJXSg1ILqfjZLfNpePa1xtjKKysJ6uwij0FVWQdqyKrsJoP9xyjre0aGuhkTEI44xLCGRsfzrghEYxLCCcqxP++1asteqWUz6htaGZfUTX7jllTVmEV+4qqT578BYgNC2KEO4Th7lDrMTb05HLkIJeN1Z8fbdErpfxCaFAAM4ZFM2NY9Ml1xhiKqxvYe6yafceqOFhSy6HSWjbmlPLOjvpTnh8d4iIlNpSRcWGMHBxmPcaFMiwmZECPBNKgV0r5NBEhPiKY+IhgLhkTd8q2usYWjpSfILeslsNltRwqPcGh0ho+3l/CX7fnndzP5bROII+MC2Xa0Ghmp8QwOSlywFzRU4NeKeW3BgU6GZsQztiE8NO2VdY1cbCkhgMltRwoqeFAcQ37i2r4MLMIsIaBTveE/uyUGKYPiyIk0Dsj1TurUkopm0UOcjF9WDTTO3QDAZTWNJCeW86WQ+Vsyy3nufXZtBoIcAiTkiKZNjTq5Je/UmNDvWLkj56MVUqp81Bd38T2w8fZllvOttzj7M6v5ERjCwDhQQFM9oT+1ORIJiVFkhw9qE++9KUnY5VSqo+EB7tYMNa6YidYl3w4UFLDzqMVZORVkJFXyR//dZCmFqtRHRroZHR8OGPiwxgTH87oeGv4Z3xEUJ9967dbLXoRWQI8CziBPxhjnuq0PQh4BZgJlAG3GGNyO2wfBuwBfmaM+dXZ3ktb9EopX9PQ3EJWYTWZBZVkF9Wwv6ia/UXVlNY0ntwnPDiABWMH89xt03v0HufVohcRJ/A8sBjIA7aJyHvGmD0ddrsHOG6MGSUitwK/AG7psP3XwD97VL1SSg1wQQFOpg2NYtrQqFPWl9c2ngz9/UXVfTaOvztdN7OBHGPMQQAReQO4DquF3uY64Gee+beB34qIGGOMiFwPHAJqe6topZTyBTGhgcxNdTM31d2n79OdQaBJwNEOy3medV3uY4xpBioBt4iEAY8BT5x/qUoppXqir0f7/wx42hhTc7adROQ+EUkXkfSSkpI+LkkppfxLd7pu8oGhHZaTPeu62idPRAKASKyTsnOAG0Xkl0AU0Coi9caY33Z8sjFmObAcrJOxPfg5lFJKnUF3gn4bMFpEUrAC/Vbg9k77vAfcDWwCbgTWG2s4z/y2HUTkZ0BN55BXSinVt74y6I0xzSLyIPAh1vDKFcaYTBF5Ekg3xrwH/BF4VURygHKsDwOllFJeQL8Zq5RSPuBs4+gHxqXXlFJK9ZgGvVJK+Tiv67oRkRLg8Hm8RCxQ2kvl9DatrWe0tp7R2npmoNY23BgT19UGrwv68yUi6Wfqp7Kb1tYzWlvPaG0944u1adeNUkr5OA16pZTycb4Y9MvtLuAstLae0dp6RmvrGZ+rzef66JVSSp3KF1v0SimlOtCgV0opH+czQS8iS0Rkn4jkiMgyu+vpSERyRWSXiOwUEduv7yAiK0SkWER2d1gXIyIfiUi25zHaS+r6mYjke47dThG5qr/r8tQxVEQ2iMgeEckUkYc9673huJ2pNtuPnYgEi8hWEfnSU9sTnvUpIrLF8/v6pogEelFtL4vIoQ7HbVp/19ahRqeIfCEi73uWe3bcjDEDfsK62NoBIBUIBL4EJthdV4f6coFYu+voUM/FwAxgd4d1vwSWeeaXAb/wkrp+BjziBcdsCDDDMx8O7AcmeMlxO1Ntth87QIAwz7wL2ALMBd4CbvWsfxG434tqexm40e7/c566/gN4DXjfs9yj4+YrLfqTtzs0xjQCbbc7VF0wxnyKdZXRjq4D/uyZ/zNwfX/WBGesyysYYwqNMTs889VAFtad1bzhuJ2pNtsZS9uNh1yeyQCXYt12FOw7bmeqzSuISDJwNfAHz7LQw+PmK0Hfndsd2skAa0Rku4jcZ3cxZxBvjCn0zB8D4u0sppMHRSTD07XT710jnYnICGA6VgvQq45bp9rAC46dp/thJ1AMfIT113eFsW47Cjb+vnauzRjTdtz+23PcnhaRIDtqA54B/hNo9Sy76eFx85Wg93YXGWNmAFcCD4jIxXYXdDbG+rvQW1o2vwNGAtOAQuB/7CzGcx/kd4B/N8ZUddxm93HrojavOHbGmBZjzDSsu9PNBsbZUUdXOtcmIpOAx7FqnAXEYN33ul+JyFKg2BizvTdez1eCvju3O7SNMSbf81gM/B3rP7u3KRKRIQCex2Kb6wHAGFPk+WVsBV7CxmMnIi6sIP2LMeZvntVecdy6qs2bjp2nngpgA3ABEOW57Sh4we9rh9qWeLrCjDGmAfgT9hy3ecC1IpKL1RV9KfAsPTxuvhL0J2936DkLfSvW7Q1tJyKhIhLeNg9cDuw++7Ns0XY7SDyP79pYy0ltIepxAzYdO0//6B+BLGPMrztssv24nak2bzh2IhInIlGe+UHAYqxzCBuwbjsK9h23rmrb2+GDW7D6wPv9uBljHjfGJBtjRmDl2XpjzB309LjZfVa5F89OX4U12uAA8CO76+lQVyrWKKAvgUxvqA14HetP+Sasfr57sPr/1gHZwFogxkvqehXYBWRgheoQm47ZRVjdMhnATs90lZcctzPVZvuxA6YAX3hq2A381LM+FdgK5AB/BYK8qLb1nuO2G1iJZ2SOXROwgPZRNz06bnoJBKWU8nG+0nWjlFLqDDTolVLKx2nQK6WUj9OgV0opH6dBr5RSPk6DXimlfJwGvVJK+bj/H/uaPWXsBNrHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score of the train set : 0.9017211682271217\n",
      "R2 score of the train set : -0.03949246226593828\n",
      "MAE score of the train set : 2.588935250947583\n",
      "MAE score of the test set : 7.6199559540985335\n"
     ]
    }
   ],
   "source": [
    "evalset = [(X_train, y_train), (X_test,y_test)]\n",
    "model = XGBRegressor(n_estimators = 40, max_depth = 5, \n",
    "                     reg_alpha = 0.5, reg_lambda = 1.5,\n",
    "                     colsample_bytree = 0.7, gamma = 0, eta = 0.3)\n",
    "\n",
    "model.fit(X_train, y_train, eval_set = evalset, verbose = 0)\n",
    "results = model.evals_result()\n",
    "plt.plot(results['validation_0']['rmse'], label='train')\n",
    "plt.plot(results['validation_1']['rmse'], label='test')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "pred_train = winloss_win(model.predict(X_train))\n",
    "pred_test = winloss_win(model.predict(X_test))\n",
    "y_train_win = winloss_win(y_train)\n",
    "y_test_win = winloss_win(y_test)\n",
    "\n",
    "print(f\"R2 score of the train set : {r2_score(pred_train, y_train_win)}\")\n",
    "print(f\"R2 score of the train set : {r2_score(pred_test, y_test_win)}\")\n",
    "print(f\"MAE score of the train set : {mean_absolute_error(pred_train, y_train_win)}\")\n",
    "print(f\"MAE score of the test set : {mean_absolute_error(pred_test, y_test_win)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tm</th>\n",
       "      <th>Year</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Real</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>BOS</td>\n",
       "      <td>2023</td>\n",
       "      <td>49.015827</td>\n",
       "      <td>56.990</td>\n",
       "      <td>7.974173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>NYK</td>\n",
       "      <td>2023</td>\n",
       "      <td>37.348888</td>\n",
       "      <td>46.986</td>\n",
       "      <td>9.637112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2023</td>\n",
       "      <td>51.024395</td>\n",
       "      <td>41.000</td>\n",
       "      <td>-10.024395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>CLE</td>\n",
       "      <td>2023</td>\n",
       "      <td>44.195408</td>\n",
       "      <td>51.004</td>\n",
       "      <td>6.808592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>DET</td>\n",
       "      <td>2023</td>\n",
       "      <td>26.772184</td>\n",
       "      <td>16.974</td>\n",
       "      <td>-9.798184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>HOU</td>\n",
       "      <td>2023</td>\n",
       "      <td>26.080721</td>\n",
       "      <td>21.976</td>\n",
       "      <td>-4.104721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>SAS</td>\n",
       "      <td>2023</td>\n",
       "      <td>32.673000</td>\n",
       "      <td>21.976</td>\n",
       "      <td>-10.697000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>CHI</td>\n",
       "      <td>2023</td>\n",
       "      <td>42.150196</td>\n",
       "      <td>40.016</td>\n",
       "      <td>-2.134196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>DEN</td>\n",
       "      <td>2023</td>\n",
       "      <td>50.201115</td>\n",
       "      <td>52.972</td>\n",
       "      <td>2.770885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>IND</td>\n",
       "      <td>2023</td>\n",
       "      <td>31.924980</td>\n",
       "      <td>35.014</td>\n",
       "      <td>3.089020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>MIL</td>\n",
       "      <td>2023</td>\n",
       "      <td>50.781536</td>\n",
       "      <td>57.974</td>\n",
       "      <td>7.192464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>GSW</td>\n",
       "      <td>2023</td>\n",
       "      <td>51.921814</td>\n",
       "      <td>44.034</td>\n",
       "      <td>-7.887814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>LAL</td>\n",
       "      <td>2023</td>\n",
       "      <td>46.437157</td>\n",
       "      <td>42.968</td>\n",
       "      <td>-3.469157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>PHO</td>\n",
       "      <td>2023</td>\n",
       "      <td>57.093983</td>\n",
       "      <td>45.018</td>\n",
       "      <td>-12.075983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>POR</td>\n",
       "      <td>2023</td>\n",
       "      <td>26.783993</td>\n",
       "      <td>32.964</td>\n",
       "      <td>6.180007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>UTA</td>\n",
       "      <td>2023</td>\n",
       "      <td>38.349613</td>\n",
       "      <td>36.982</td>\n",
       "      <td>-1.367613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>DAL</td>\n",
       "      <td>2023</td>\n",
       "      <td>50.045532</td>\n",
       "      <td>37.966</td>\n",
       "      <td>-12.079532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>LAC</td>\n",
       "      <td>2023</td>\n",
       "      <td>40.083157</td>\n",
       "      <td>44.034</td>\n",
       "      <td>3.950843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>SAC</td>\n",
       "      <td>2023</td>\n",
       "      <td>28.774220</td>\n",
       "      <td>47.970</td>\n",
       "      <td>19.195780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>MIA</td>\n",
       "      <td>2023</td>\n",
       "      <td>52.601192</td>\n",
       "      <td>44.034</td>\n",
       "      <td>-8.567192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>ORL</td>\n",
       "      <td>2023</td>\n",
       "      <td>23.855364</td>\n",
       "      <td>34.030</td>\n",
       "      <td>10.174636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>MIN</td>\n",
       "      <td>2023</td>\n",
       "      <td>47.552071</td>\n",
       "      <td>41.984</td>\n",
       "      <td>-5.568071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>TOR</td>\n",
       "      <td>2023</td>\n",
       "      <td>46.260719</td>\n",
       "      <td>41.000</td>\n",
       "      <td>-5.260719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>WAS</td>\n",
       "      <td>2023</td>\n",
       "      <td>34.406471</td>\n",
       "      <td>35.014</td>\n",
       "      <td>0.607529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>MEM</td>\n",
       "      <td>2023</td>\n",
       "      <td>48.341179</td>\n",
       "      <td>51.004</td>\n",
       "      <td>2.662821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>OKC</td>\n",
       "      <td>2023</td>\n",
       "      <td>28.533949</td>\n",
       "      <td>40.016</td>\n",
       "      <td>11.482051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>BRK</td>\n",
       "      <td>2023</td>\n",
       "      <td>46.676769</td>\n",
       "      <td>45.018</td>\n",
       "      <td>-1.658769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>NOP</td>\n",
       "      <td>2023</td>\n",
       "      <td>36.541817</td>\n",
       "      <td>41.984</td>\n",
       "      <td>5.442183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>CHO</td>\n",
       "      <td>2023</td>\n",
       "      <td>39.382812</td>\n",
       "      <td>26.978</td>\n",
       "      <td>-12.404812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tm  Year       Pred    Real      Error\n",
       "1062  BOS  2023  49.015827  56.990   7.974173\n",
       "1063  NYK  2023  37.348888  46.986   9.637112\n",
       "1064  ATL  2023  51.024395  41.000 -10.024395\n",
       "1065  CLE  2023  44.195408  51.004   6.808592\n",
       "1066  DET  2023  26.772184  16.974  -9.798184\n",
       "1067  HOU  2023  26.080721  21.976  -4.104721\n",
       "1068  SAS  2023  32.673000  21.976 -10.697000\n",
       "1069  CHI  2023  42.150196  40.016  -2.134196\n",
       "1070  DEN  2023  50.201115  52.972   2.770885\n",
       "1071  IND  2023  31.924980  35.014   3.089020\n",
       "1072  MIL  2023  50.781536  57.974   7.192464\n",
       "1073  GSW  2023  51.921814  44.034  -7.887814\n",
       "1074  LAL  2023  46.437157  42.968  -3.469157\n",
       "1075  PHO  2023  57.093983  45.018 -12.075983\n",
       "1076  POR  2023  26.783993  32.964   6.180007\n",
       "1077  UTA  2023  38.349613  36.982  -1.367613\n",
       "1078  DAL  2023  50.045532  37.966 -12.079532\n",
       "1079  LAC  2023  40.083157  44.034   3.950843\n",
       "1080  SAC  2023  28.774220  47.970  19.195780\n",
       "1081  MIA  2023  52.601192  44.034  -8.567192\n",
       "1082  ORL  2023  23.855364  34.030  10.174636\n",
       "1083  MIN  2023  47.552071  41.984  -5.568071\n",
       "1084  TOR  2023  46.260719  41.000  -5.260719\n",
       "1085  WAS  2023  34.406471  35.014   0.607529\n",
       "1086  MEM  2023  48.341179  51.004   2.662821\n",
       "1087  OKC  2023  28.533949  40.016  11.482051\n",
       "1088  BRK  2023  46.676769  45.018  -1.658769\n",
       "1089  NOP  2023  36.541817  41.984   5.442183\n",
       "1090  CHO  2023  39.382812  26.978 -12.404812"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = df[(df.Year >= 2014)]\n",
    "pred_df = pred_df[[\"Tm\", \"Year\"]]\n",
    "pred_df[\"Pred\"] = winloss_win(model.predict(X_test))\n",
    "pred_df[\"Real\"] = winloss_win(y_test)\n",
    "pred_df[\"Error\"] = pred_df.Real - pred_df.Pred\n",
    "pred_df[(pred_df.Year == 2023)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"data/pred_test_XGB.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=4, test_size=188, gap = 0)\n",
    "\n",
    "num_estimators= [i for i in range(20, 121, 20)]\n",
    "min_samples_split = [2, 3, 5, 7]\n",
    "min_samples_leaf = [1, 3, 5]\n",
    "max_features = [\"sqrt\", \"log2\", 1]\n",
    "\n",
    "score = []\n",
    "for num_esti in num_estimators:\n",
    "    for mss in min_samples_split:\n",
    "        for msl in min_samples_leaf:\n",
    "            for mf in max_features:\n",
    "                res = [num_esti, mss, msl, mf]\n",
    "                rmse = []\n",
    "                ratio = 1\n",
    "                for train_index, test_index in tscv.split(X_train):\n",
    "                    cv_train, cv_val = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "                    cv_y_train, cv_y_val = y_train[train_index], y_train[test_index]\n",
    "                    model = RandomForestRegressor(n_estimators = num_esti, min_samples_split = mss, \n",
    "                                                  min_samples_leaf = msl, max_features = mf)\n",
    "                    model.fit(cv_train, cv_y_train) \n",
    "                    rmse.append(ratio*np.sqrt(mean_squared_error(model.predict(cv_val), cv_y_val)))\n",
    "                    ratio +=1\n",
    "                res.append(np.sum(rmse)/10)\n",
    "                score.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_estimators             20\n",
      "min_samples_split           5\n",
      "min_samples_leaf            5\n",
      "max_features                1\n",
      "rmse                 0.131192\n",
      "Name: 26, dtype: object\n",
      "R2 score of the train set : 0.029934159092685042\n",
      "R2 score of the train set : -1.0102497588028614\n",
      "MAE score of the train set : 5.998333225133172\n",
      "MAE score of the test set : 7.701661440997459\n"
     ]
    }
   ],
   "source": [
    "score = pd.DataFrame(score, columns = [\"num_estimators\", \"min_samples_split\", \"min_samples_leaf\", \"max_features\", \"rmse\"])\n",
    "score.sort_values(by=['rmse'], ascending=False, inplace = True)\n",
    "best_params = list(score.iloc[0, :])[:-1]\n",
    "print(score.iloc[0, :])\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = int(best_params[0]), min_samples_split = int(best_params[1]), \n",
    "                     min_samples_leaf = int(best_params[2]), max_features = int(best_params[3]))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred_train = winloss_win(model.predict(X_train))\n",
    "pred_test = winloss_win(model.predict(X_test))\n",
    "y_train_win = winloss_win(y_train)\n",
    "y_test_win = winloss_win(y_test)\n",
    "\n",
    "print(f\"R2 score of the train set : {r2_score(pred_train, y_train_win)}\")\n",
    "print(f\"R2 score of the train set : {r2_score(pred_test, y_test_win)}\")\n",
    "print(f\"MAE score of the train set : {mean_absolute_error(pred_train, y_train_win)}\")\n",
    "print(f\"MAE score of the test set : {mean_absolute_error(pred_test, y_test_win)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour éviter de ReRUn le Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score of the train set : 0.14059373736309788\n",
      "R2 score of the train set : -0.8430170971724091\n",
      "MAE score of the train set : 5.806346852720734\n",
      "MAE score of the test set : 7.90661101350718\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators = 20, min_samples_split = 5, \n",
    "                     min_samples_leaf = 5, max_features = 1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred_train = winloss_win(model.predict(X_train))\n",
    "pred_test = winloss_win(model.predict(X_test))\n",
    "y_train_win = winloss_win(y_train)\n",
    "y_test_win = winloss_win(y_test)\n",
    "\n",
    "print(f\"R2 score of the train set : {r2_score(pred_train, y_train_win)}\")\n",
    "print(f\"R2 score of the train set : {r2_score(pred_test, y_test_win)}\")\n",
    "print(f\"MAE score of the train set : {mean_absolute_error(pred_train, y_train_win)}\")\n",
    "print(f\"MAE score of the test set : {mean_absolute_error(pred_test, y_test_win)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tm</th>\n",
       "      <th>Year</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Real</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>BOS</td>\n",
       "      <td>2023</td>\n",
       "      <td>49.974462</td>\n",
       "      <td>56.990</td>\n",
       "      <td>7.015538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>NYK</td>\n",
       "      <td>2023</td>\n",
       "      <td>38.648295</td>\n",
       "      <td>46.986</td>\n",
       "      <td>8.337705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>ATL</td>\n",
       "      <td>2023</td>\n",
       "      <td>45.512265</td>\n",
       "      <td>41.000</td>\n",
       "      <td>-4.512265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>CLE</td>\n",
       "      <td>2023</td>\n",
       "      <td>40.201754</td>\n",
       "      <td>51.004</td>\n",
       "      <td>10.802246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>DET</td>\n",
       "      <td>2023</td>\n",
       "      <td>30.874789</td>\n",
       "      <td>16.974</td>\n",
       "      <td>-13.900789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>HOU</td>\n",
       "      <td>2023</td>\n",
       "      <td>31.521358</td>\n",
       "      <td>21.976</td>\n",
       "      <td>-9.545358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>SAS</td>\n",
       "      <td>2023</td>\n",
       "      <td>36.610308</td>\n",
       "      <td>21.976</td>\n",
       "      <td>-14.634308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>CHI</td>\n",
       "      <td>2023</td>\n",
       "      <td>44.632806</td>\n",
       "      <td>40.016</td>\n",
       "      <td>-4.616806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>DEN</td>\n",
       "      <td>2023</td>\n",
       "      <td>47.425151</td>\n",
       "      <td>52.972</td>\n",
       "      <td>5.546849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>IND</td>\n",
       "      <td>2023</td>\n",
       "      <td>32.016593</td>\n",
       "      <td>35.014</td>\n",
       "      <td>2.997407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>MIL</td>\n",
       "      <td>2023</td>\n",
       "      <td>50.315919</td>\n",
       "      <td>57.974</td>\n",
       "      <td>7.658081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>GSW</td>\n",
       "      <td>2023</td>\n",
       "      <td>47.725427</td>\n",
       "      <td>44.034</td>\n",
       "      <td>-3.691427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>LAL</td>\n",
       "      <td>2023</td>\n",
       "      <td>45.870960</td>\n",
       "      <td>42.968</td>\n",
       "      <td>-2.902960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>PHO</td>\n",
       "      <td>2023</td>\n",
       "      <td>48.031623</td>\n",
       "      <td>45.018</td>\n",
       "      <td>-3.013623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>POR</td>\n",
       "      <td>2023</td>\n",
       "      <td>35.309233</td>\n",
       "      <td>32.964</td>\n",
       "      <td>-2.345233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>UTA</td>\n",
       "      <td>2023</td>\n",
       "      <td>46.454938</td>\n",
       "      <td>36.982</td>\n",
       "      <td>-9.472938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>DAL</td>\n",
       "      <td>2023</td>\n",
       "      <td>44.299848</td>\n",
       "      <td>37.966</td>\n",
       "      <td>-6.333848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>LAC</td>\n",
       "      <td>2023</td>\n",
       "      <td>46.061143</td>\n",
       "      <td>44.034</td>\n",
       "      <td>-2.027143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>SAC</td>\n",
       "      <td>2023</td>\n",
       "      <td>31.308485</td>\n",
       "      <td>47.970</td>\n",
       "      <td>16.661515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>MIA</td>\n",
       "      <td>2023</td>\n",
       "      <td>47.793323</td>\n",
       "      <td>44.034</td>\n",
       "      <td>-3.759323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>ORL</td>\n",
       "      <td>2023</td>\n",
       "      <td>27.575637</td>\n",
       "      <td>34.030</td>\n",
       "      <td>6.454363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>MIN</td>\n",
       "      <td>2023</td>\n",
       "      <td>46.417026</td>\n",
       "      <td>41.984</td>\n",
       "      <td>-4.433026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>TOR</td>\n",
       "      <td>2023</td>\n",
       "      <td>47.205051</td>\n",
       "      <td>41.000</td>\n",
       "      <td>-6.205051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>WAS</td>\n",
       "      <td>2023</td>\n",
       "      <td>39.377581</td>\n",
       "      <td>35.014</td>\n",
       "      <td>-4.363581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>MEM</td>\n",
       "      <td>2023</td>\n",
       "      <td>41.108810</td>\n",
       "      <td>51.004</td>\n",
       "      <td>9.895190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>OKC</td>\n",
       "      <td>2023</td>\n",
       "      <td>29.445692</td>\n",
       "      <td>40.016</td>\n",
       "      <td>10.570308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>BRK</td>\n",
       "      <td>2023</td>\n",
       "      <td>46.542874</td>\n",
       "      <td>45.018</td>\n",
       "      <td>-1.524874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>NOP</td>\n",
       "      <td>2023</td>\n",
       "      <td>38.455409</td>\n",
       "      <td>41.984</td>\n",
       "      <td>3.528591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>CHO</td>\n",
       "      <td>2023</td>\n",
       "      <td>40.361389</td>\n",
       "      <td>26.978</td>\n",
       "      <td>-13.383389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tm  Year       Pred    Real      Error\n",
       "1062  BOS  2023  49.974462  56.990   7.015538\n",
       "1063  NYK  2023  38.648295  46.986   8.337705\n",
       "1064  ATL  2023  45.512265  41.000  -4.512265\n",
       "1065  CLE  2023  40.201754  51.004  10.802246\n",
       "1066  DET  2023  30.874789  16.974 -13.900789\n",
       "1067  HOU  2023  31.521358  21.976  -9.545358\n",
       "1068  SAS  2023  36.610308  21.976 -14.634308\n",
       "1069  CHI  2023  44.632806  40.016  -4.616806\n",
       "1070  DEN  2023  47.425151  52.972   5.546849\n",
       "1071  IND  2023  32.016593  35.014   2.997407\n",
       "1072  MIL  2023  50.315919  57.974   7.658081\n",
       "1073  GSW  2023  47.725427  44.034  -3.691427\n",
       "1074  LAL  2023  45.870960  42.968  -2.902960\n",
       "1075  PHO  2023  48.031623  45.018  -3.013623\n",
       "1076  POR  2023  35.309233  32.964  -2.345233\n",
       "1077  UTA  2023  46.454938  36.982  -9.472938\n",
       "1078  DAL  2023  44.299848  37.966  -6.333848\n",
       "1079  LAC  2023  46.061143  44.034  -2.027143\n",
       "1080  SAC  2023  31.308485  47.970  16.661515\n",
       "1081  MIA  2023  47.793323  44.034  -3.759323\n",
       "1082  ORL  2023  27.575637  34.030   6.454363\n",
       "1083  MIN  2023  46.417026  41.984  -4.433026\n",
       "1084  TOR  2023  47.205051  41.000  -6.205051\n",
       "1085  WAS  2023  39.377581  35.014  -4.363581\n",
       "1086  MEM  2023  41.108810  51.004   9.895190\n",
       "1087  OKC  2023  29.445692  40.016  10.570308\n",
       "1088  BRK  2023  46.542874  45.018  -1.524874\n",
       "1089  NOP  2023  38.455409  41.984   3.528591\n",
       "1090  CHO  2023  40.361389  26.978 -13.383389"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = df[(df.Year >= 2014)]\n",
    "pred_df = pred_df[[\"Tm\", \"Year\"]]\n",
    "pred_df[\"Pred\"] = winloss_win(model.predict(X_test))\n",
    "pred_df[\"Real\"] = winloss_win(y_test)\n",
    "pred_df[\"Error\"] = pred_df.Real - pred_df.Pred\n",
    "pred_df[(pred_df.Year == 2023)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"data/pred_test_RF.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "\n",
    "df_no_nan = df.dropna()\n",
    "first_df = df_no_nan[(df_no_nan.Year <= 2013)]\n",
    "y_train = np.array(first_df.WinLoss)\n",
    "X_train = first_df.drop([\"WinLoss\", \"Year\", \"Tm\"], axis = 1)\n",
    "second_df = df_no_nan[(df_no_nan.Year >= 2014)]\n",
    "y_test = np.array(second_df.WinLoss)\n",
    "X_test = second_df.drop([\"WinLoss\", \"Year\", \"Tm\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=4, test_size=100, gap = 0)\n",
    "\n",
    "max_depth = [3, 4, 5, 6, 7, 10, 15, 17, 20]\n",
    "min_samples_split = [2, 5, 7, 10]\n",
    "min_samples_leaf = [1, 5, 10, 15] \n",
    "criterion = ['squared_error', 'absolute_error', 'poisson']\n",
    "\n",
    "score = []\n",
    "for md in max_depth:\n",
    "    for split in min_samples_split:\n",
    "        for leaf in min_samples_leaf:\n",
    "            for crt in criterion:\n",
    "                res = [md, split, leaf, crt]\n",
    "                rmse = []\n",
    "                ratio = 1\n",
    "                for train_index, test_index in tscv.split(X_train):\n",
    "                    cv_train, cv_val = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "                    cv_y_train, cv_y_val = y_train[train_index], y_train[test_index]\n",
    "                    model = DecisionTreeRegressor(max_depth = md, min_samples_split = split, min_samples_leaf = leaf, criterion = crt)\n",
    "                    model.fit(cv_train, cv_y_train) \n",
    "                    rmse.append(ratio*np.sqrt(mean_squared_error(model.predict(cv_val), cv_y_val)))\n",
    "                    ratio +=1\n",
    "                res.append(np.sum(rmse)/10)\n",
    "                score.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth                       20\n",
      "min_samples_split                2\n",
      "min_samples_leaf                 1\n",
      "criterion            squared_error\n",
      "rmse                      0.165663\n",
      "Name: 384, dtype: object\n",
      "R2 score of the train set : 0.9999880204753768\n",
      "R2 score of the test set : 0.10670031948448522\n",
      "MAE score of the train set : 0.003765306122449041\n",
      "MAE score of the test set : 9.218821917808219\n"
     ]
    }
   ],
   "source": [
    "# Final predictions\n",
    "\n",
    "score = pd.DataFrame(score, columns = [\"max_depth\", \"min_samples_split\", \"min_samples_leaf\", \"criterion\", \"rmse\"])\n",
    "score.sort_values(by=['rmse'], ascending=False, inplace = True)\n",
    "best_params = list(score.iloc[0, :])[:-1]\n",
    "print(score.iloc[0, :])\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth = int(best_params[0]), min_samples_split = int(best_params[1]), \n",
    "                              min_samples_leaf = int(best_params[2]), criterion = best_params[3])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred_train = winloss_win(model.predict(X_train))\n",
    "pred_test = winloss_win(model.predict(X_test))\n",
    "y_train_win = winloss_win(y_train)\n",
    "y_test_win = winloss_win(y_test)\n",
    "\n",
    "print(f\"R2 score of the train set : {r2_score(pred_train, y_train_win)}\")\n",
    "print(f\"R2 score of the test set : {r2_score(pred_test, y_test_win)}\")\n",
    "print(f\"MAE score of the train set : {mean_absolute_error(pred_train, y_train_win)}\")\n",
    "print(f\"MAE score of the test set : {mean_absolute_error(pred_test, y_test_win)}\")\n",
    "\n",
    "output = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tm  Year  ActualWinLoss  Pred_WinLoss\n",
      "0  BOS  1984          0.756         0.756\n",
      "1  NJN  1984          0.549         0.549\n",
      "2  NYK  1984          0.573         0.573\n",
      "3  PHI  1984          0.634         0.634\n",
      "4  WSB  1984          0.427         0.427\n"
     ]
    }
   ],
   "source": [
    "# Predictions to CSV \n",
    "\n",
    "output_train = first_df[[\"Tm\", \"Year\", \"WinLoss\"]].copy()\n",
    "output_train.rename(columns={\"WinLoss\": \"ActualWinLoss\"}, inplace=True)\n",
    "output_train[\"Pred_WinLoss\"] = pred_train/82\n",
    "\n",
    "output_test = second_df[[\"Tm\", \"Year\", \"WinLoss\"]].copy()\n",
    "output_test.rename(columns={\"WinLoss\": \"ActualWinLoss\"}, inplace=True)\n",
    "output_test[\"Pred_WinLoss\"] = pred_test/82\n",
    "\n",
    "output = pd.concat([output_train, output_test], axis=0)\n",
    "print(output.head())\n",
    "output.to_csv('CART_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
